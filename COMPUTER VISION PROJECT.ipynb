{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7b88a2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Load the 'images.npy' file with allow_pickle=True\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m images_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mImages.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m, allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Print the contents of the 'images.npy' file\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(images_data)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\lib\\npyio.py:432\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    429\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mopen_memmap(file, mode\u001b[38;5;241m=\u001b[39mmmap_mode,\n\u001b[0;32m    430\u001b[0m                                   max_header_size\u001b[38;5;241m=\u001b[39mmax_header_size)\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 432\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mread_array(fid, allow_pickle\u001b[38;5;241m=\u001b[39mallow_pickle,\n\u001b[0;32m    433\u001b[0m                                  pickle_kwargs\u001b[38;5;241m=\u001b[39mpickle_kwargs,\n\u001b[0;32m    434\u001b[0m                                  max_header_size\u001b[38;5;241m=\u001b[39mmax_header_size)\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\lib\\format.py:792\u001b[0m, in \u001b[0;36mread_array\u001b[1;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[0;32m    790\u001b[0m     pickle_kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    791\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 792\u001b[0m     array \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(fp, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_kwargs)\n\u001b[0;32m    793\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    794\u001b[0m     \u001b[38;5;66;03m# Friendlier error message\u001b[39;00m\n\u001b[0;32m    795\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mUnicodeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnpickling a python object failed: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    796\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou may need to pass the encoding= option \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    797\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto numpy.load\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (err,)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 1.1A-\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Load the 'images.npy' file with allow_pickle=True\n",
    "images_data = np.load(r\"C:\\Users\\user\\Downloads\\Images.npy\", allow_pickle=True)\n",
    "\n",
    "# Print the contents of the 'images.npy' file\n",
    "print(images_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba43cfe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Print the first few elements to understand their structure\n",
    "for i in range(5):\n",
    "    print(\"Element\", i, \":\", images_data[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca68d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1B-\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# Step 1: Separate image arrays and annotations\n",
    "image_arrays = [element[0] for element in images_data]\n",
    "annotations = [element[1] for element in images_data]\n",
    "\n",
    "# Step 2: Resize all images to a unified shape (assuming desired_shape is (224, 224))\n",
    "desired_shape = (224, 224)\n",
    "\n",
    "resized_images = []\n",
    "for image in image_arrays:\n",
    "    img = Image.fromarray(image)\n",
    "    img = img.resize(desired_shape, Image.ANTIALIAS)  # Resize while preserving aspect ratio\n",
    "    resized_images.append(np.array(img))\n",
    "\n",
    "# Step 3: Create binary masks for each image, replacing pixels within the masked area with 1\n",
    "masked_images = []\n",
    "for img, annotation in zip(resized_images, annotations):\n",
    "    mask = Image.new('L', img.shape[:2], 0)  # Create a black mask\n",
    "    draw = ImageDraw.Draw(mask)\n",
    "    for obj in annotation:\n",
    "        if 'Face' in obj['label']:\n",
    "            points = [(point['x'] * img.shape[1], point['y'] * img.shape[0]) for point in obj['points']]\n",
    "            draw.polygon(points, fill=1)  # Fill the polygon representing the face with 1 in the mask\n",
    "    masked_images.append(np.array(mask))\n",
    "\n",
    "# Step 4: Extract features (X) and labels (Y)\n",
    "X = np.array(masked_images)\n",
    "Y = np.array(masked_images)  # Use the same mask as labels\n",
    "\n",
    "# Check shapes\n",
    "print(\"Shape of X (features):\", X.shape)\n",
    "print(\"Shape of Y (labels):\", Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b228942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1C-\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X and Y are the features and labels arrays created earlier\n",
    "\n",
    "# Split the data into 70% train and 30% test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting datasets\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of Y_train:\", Y_train.shape)\n",
    "print(\"Shape of Y_test:\", Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9873a16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2ff24b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c487a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7bf0e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491d939f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1.2A-\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, UpSampling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Normalize X\n",
    "X = X / 255.0\n",
    "\n",
    "# Ensure Y is binary\n",
    "Y = (Y > 0).astype(np.float32)\n",
    "\n",
    "# Add channel dimension to X to match input shape requirements of the model\n",
    "X = np.expand_dims(X, axis=-1) if X.ndim == 3 else X\n",
    "Y = np.expand_dims(Y, axis=-1) if Y.ndim == 3 else Y\n",
    "\n",
    "# Further split the training data into train and validation sets\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Model Design\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(1, (1, 1), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Step 3: Model Compilation\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Model Training\n",
    "history = model.fit(\n",
    "    X_train, Y_train,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, Y_val)\n",
    ")\n",
    "\n",
    "# Step 5: Model Evaluation\n",
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777e5aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2A\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.layers import Conv2D, UpSampling2D, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (224, 224, 3)\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "# Load the MobileNet model with pre-trained weights\n",
    "base_model = MobileNet(input_shape=input_shape, include_top=False, weights='imagenet')\n",
    "\n",
    "# Freeze the MobileNet layers\n",
    "base_model.trainable = False\n",
    "\n",
    "# Encoder: Get the output of the base model\n",
    "encoder_output = base_model.output  # 7x7\n",
    "\n",
    "# Decoder: Upsampling path without concatenation\n",
    "up1 = UpSampling2D(size=(2, 2))(encoder_output)\n",
    "up1 = Conv2D(256, (3, 3), activation='relu', padding='same')(up1)\n",
    "up1 = Conv2D(256, (3, 3), activation='relu', padding='same')(up1)  # 14x14\n",
    "\n",
    "up2 = UpSampling2D(size=(2, 2))(up1)\n",
    "up2 = Conv2D(128, (3, 3), activation='relu', padding='same')(up2)\n",
    "up2 = Conv2D(128, (3, 3), activation='relu', padding='same')(up2)  # 28x28\n",
    "\n",
    "up3 = UpSampling2D(size=(2, 2))(up2)\n",
    "up3 = Conv2D(64, (3, 3), activation='relu', padding='same')(up3)\n",
    "up3 = Conv2D(64, (3, 3), activation='relu', padding='same')(up3)  # 56x56\n",
    "\n",
    "up4 = UpSampling2D(size=(2, 2))(up3)\n",
    "up4 = Conv2D(32, (3, 3), activation='relu', padding='same')(up4)\n",
    "up4 = Conv2D(32, (3, 3), activation='relu', padding='same')(up4)  # 112x112\n",
    "\n",
    "up5 = UpSampling2D(size=(2, 2))(up4)\n",
    "up5 = Conv2D(16, (3, 3), activation='relu', padding='same')(up5)\n",
    "up5 = Conv2D(16, (3, 3), activation='relu', padding='same')(up5)  # 224x224\n",
    "\n",
    "# Output layer\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid')(up5)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4a63cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2B-\n",
    "\n",
    "def dice_coefficient(y_true, y_pred, smooth=1e-6):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    return (2.0 * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb1002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2C-\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, UpSampling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Normalize X\n",
    "X = X / 255.0\n",
    "\n",
    "# Ensure Y is binary\n",
    "Y = (Y > 0).astype(np.float32)\n",
    "\n",
    "# Add channel dimension to X to match input shape requirements of the model\n",
    "X = np.expand_dims(X, axis=-1) if X.ndim == 3 else X\n",
    "Y = np.expand_dims(Y, axis=-1) if Y.ndim == 3 else Y\n",
    "\n",
    "# Further split the training data into train and validation sets\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Model Design\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    UpSampling2D((2, 2)),\n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    Conv2D(1, (1, 1), activation='sigmoid', padding='same')\n",
    "])\n",
    "\n",
    "# Step 3: Model Compilation\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Define Callbacks\n",
    "checkpoint = ModelCheckpoint(\"best_model.keras\", monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6, verbose=1)\n",
    "\n",
    "callbacks = [checkpoint, early_stopping, reduce_lr]\n",
    "\n",
    "# Step 5: Train the Model\n",
    "history = model.fit(\n",
    "    X_train, Y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, Y_val),\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# Step 6: Evaluate the Model\n",
    "loss, accuracy = model.evaluate(X_test, Y_test)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b464e43b",
   "metadata": {},
   "source": [
    "Model 1 (Epochs: 10)\n",
    "\n",
    "    Training Loss: Started with a high loss of around 3.83 and gradually decreased to about 1.99.\n",
    "    Training Accuracy: Improved from approximately 63% to 87%.\n",
    "    Validation Loss: Initially started at 2.237 and remained constant throughout training.\n",
    "    Validation Accuracy: Stayed at around 86% throughout training.\n",
    "    Test Loss: 2.122\n",
    "    Test Accuracy: 86.72%\n",
    "    \n",
    "    \n",
    "Model 2 (Epochs: 20)\n",
    "\n",
    "    Training Loss: Started at 0.617 and decreased to around 0.35.\n",
    "    Training Accuracy: Improved from approximately 85% to 87.78%.\n",
    "    Validation Loss: Decreased from 0.4278 to 0.3776.\n",
    "    Validation Accuracy: Stayed around 85.96%.\n",
    "    Test Loss: 2.122\n",
    "    Test Accuracy: 86.72%\n",
    "    \n",
    "    \n",
    "Insights:\n",
    "\n",
    "    Both models achieved similar test accuracy, suggesting that they have comparable performance on unseen data.\n",
    "    Model 2 showed better convergence in terms of training and validation loss, indicating better generalization capability.\n",
    "    However, neither model showed significant improvement in validation accuracy after a certain number of epochs, suggesting that further training might not yield much improvement.\n",
    "    It seems like the models might have reached their limits in terms of learning from the provided data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faed35d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the test image with index 3 from the test data\n",
    "test_image_index = 3\n",
    "test_image = X_test[test_image_index]  # Assuming X_test contains the test images\n",
    "test_mask = Y_test[test_image_index]  # Assuming Y_test contains the corresponding masks\n",
    "\n",
    "# Visualize the test image and its mask\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Original test image\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(test_image)\n",
    "plt.title(\"Test Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "# Masked image overlay\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(test_image)\n",
    "plt.imshow(test_mask, cmap='jet', alpha=0.5)  # Overlay the mask with a color map and some transparency\n",
    "plt.title(\"Masked Image\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8304be9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65bed3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1A--\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Function to read images from folder\n",
    "def read_images_from_folder(folder_path):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        img = cv2.imread(os.path.join(folder_path, filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "        else:\n",
    "            print(\"Failed to read image:\", filename)\n",
    "    return images\n",
    "\n",
    "# Path to the folder containing images\n",
    "folder_path = r\"C:\\Users\\user\\Downloads\\training_images-20211126T092819Z-001\\training_images\"\n",
    "\n",
    "# Read images from folder\n",
    "images = read_images_from_folder(folder_path)\n",
    "\n",
    "# Check the number of images read\n",
    "print(\"Number of images read:\", len(images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3a9560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1B--\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Function to detect faces in an image\n",
    "def detect_faces(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    return faces\n",
    "\n",
    "# Path to the folder containing images\n",
    "folder_path = r\"C:\\Users\\user\\Downloads\\training_images-20211126T092819Z-001\\training_images\"\n",
    "# Output folder for images with detected faces\n",
    "output_folder = \"images_with_faces\"\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Loop through all images in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    # Read the image\n",
    "    img_path = os.path.join(folder_path, filename)\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    # Check if image was loaded successfully\n",
    "    if img is None:\n",
    "        print(\"Failed to load image:\", img_path)\n",
    "        continue\n",
    "    \n",
    "    # Detect faces in the image\n",
    "    faces = detect_faces(img)\n",
    "    \n",
    "    # Check if faces were detected\n",
    "    if len(faces) == 0:\n",
    "        print(\"No faces detected in image:\", img_path)\n",
    "        continue\n",
    "    \n",
    "    # Draw rectangles around the detected faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "    \n",
    "    # Save the image with detected faces\n",
    "    output_path = os.path.join(output_folder, filename)\n",
    "    cv2.imwrite(output_path, img)\n",
    "    print(\"Image with detected faces saved:\", output_path)\n",
    "\n",
    "print(\"Face detection completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623fd9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1C--\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Function to detect faces and extract metadata\n",
    "def detect_faces_and_metadata(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    metadata = []\n",
    "    for (x, y, w, h) in faces:\n",
    "        metadata.append({'x': x, 'y': y, 'width': w, 'height': h})\n",
    "    return metadata\n",
    "\n",
    "# Path to the folder containing images\n",
    "folder_path = r\"C:\\Users\\user\\Downloads\\training_images-20211126T092819Z-001\\training_images\"\n",
    "\n",
    "# DataFrame to store face metadata\n",
    "face_metadata_df = pd.DataFrame(columns=['Image', 'FaceMetadata'])\n",
    "\n",
    "# Loop through all images in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    # Read the image\n",
    "    img_path = os.path.join(folder_path, filename)\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    # Check if image was loaded successfully\n",
    "    if img is None:\n",
    "        print(\"Failed to load image:\", img_path)\n",
    "        continue\n",
    "    \n",
    "    # Detect faces and extract metadata\n",
    "    face_metadata = detect_faces_and_metadata(img)\n",
    "    \n",
    "    # Append face metadata to DataFrame\n",
    "    face_metadata_df = face_metadata_df.append({'Image': filename, 'FaceMetadata': face_metadata}, ignore_index=True)\n",
    "\n",
    "# Display DataFrame with face metadata\n",
    "print(\"DataFrame with face metadata:\")\n",
    "print(face_metadata_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e680a88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1D--\n",
    "\n",
    "# Define the path where you want to save the CSV file\n",
    "csv_file_path = \"face_metadata.csv\"\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "face_metadata_df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(\"DataFrame saved to CSV file:\", csv_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9674cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part1.1d--\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Load the images\n",
    "images_path = r\"C:\\Users\\user\\Downloads\\Images.npy\"  # Replace this with the actual path to your 'Images.npy' file\n",
    "images_data = np.load(images_path, allow_pickle=True)\n",
    "\n",
    "# Generate masked images\n",
    "masked_images = []\n",
    "for image_info in images_data:\n",
    "    image_array = image_info[0]\n",
    "    annotations = image_info[1]\n",
    "\n",
    "    # Convert to grayscale if necessary\n",
    "    if len(image_array.shape) > 2:\n",
    "        image_array = np.mean(image_array, axis=2).astype(np.uint8)\n",
    "\n",
    "    # Create a mask with the same dimensions as the image, filled with zeros\n",
    "    mask = np.zeros_like(image_array, dtype=np.uint8)\n",
    "\n",
    "    # Draw polygons for each face annotation\n",
    "    for annotation in annotations:\n",
    "        if 'Face' in annotation['label']:  # Assuming 'Face' label indicates face annotations\n",
    "            points = [(point['x'] * image_array.shape[1], point['y'] * image_array.shape[0]) for point in annotation['points']]\n",
    "            # Convert polygon points to integer and reshape for fillPoly\n",
    "            points = np.array(points, np.int32).reshape((-1, 1, 2))\n",
    "            cv2.fillPoly(mask, [points], color=255)\n",
    "\n",
    "    # Apply the mask to the original image\n",
    "    masked_image = cv2.bitwise_and(image_array, image_array, mask=mask)\n",
    "\n",
    "    masked_images.append(masked_image)\n",
    "\n",
    "# Visualize some images and masks\n",
    "num_samples_to_visualize = 5\n",
    "for i in range(num_samples_to_visualize):\n",
    "    plt.subplot(2, num_samples_to_visualize, i + 1)\n",
    "    plt.imshow(images_data[i][0], cmap='gray')\n",
    "    plt.title(\"Image {}\".format(i + 1))\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2, num_samples_to_visualize, num_samples_to_visualize + i + 1)\n",
    "    plt.imshow(masked_images[i], cmap='gray')\n",
    "    plt.title(\"Masked Image {}\".format(i + 1))\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
